import warnings
# warnings.filterwarnings("ignore", category=FutureWarning)
import os
from tqdm import tqdm
import wandb
os.environ["WANDB__SERVICE_WAIT"] = "300"
import torch
from torch.utils.data import DataLoader
import torch.distributed as dist
from utils.init_setup import dist_init, setup_model
import logging
from utils import logging_config
from dataloaders.random_dataset import StreamDataset
from omegaconf import OmegaConf

class FlashDepthProcessor:
    def __init__(self, config_path="configs/flashdepth"):
        self.cfg = None
        self.process_dict = None
        self.run_dir = None
        self._load_config(config_path)
        self._setup()
        
    def _load_config(self, config_path):
        """Load configuration using OmegaConf."""
        
        config_file = os.path.join(config_path, "config.yaml")
        
        if os.path.exists(config_file):
            self.cfg = OmegaConf.load(config_file)
            print(f"Loaded config from: {config_file}")
        else:
            raise FileNotFoundError(f"Config file not found: {config_file}")
        
    def _setup(self):
        # initialize distributed/process
        self.process_dict = dist_init()
        logging_config.configure_logging()

        # Only use run_dir generated by setup as the output directory for all results
        result_root = os.path.abspath(os.path.join(os.getcwd(), 'result'))
        os.makedirs(result_root, exist_ok=True)
        idx = 0
        while True:
            candidate = os.path.join(result_root, f'stream_{idx}')
            if not os.path.exists(candidate):
                os.makedirs(candidate)
                self.run_dir = candidate
                break
            idx += 1

        # Add file logger to run_dir so logs are saved to stream_{N}/run.log
        fh = logging.FileHandler(os.path.join(self.run_dir, 'run.log'))
        fh.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        logging.getLogger().addHandler(fh)

        # Set config_dir for compatibility
        if hasattr(self.cfg, 'config_dir'):
            self.cfg.config_dir = os.getcwd()
        
    @torch.no_grad()
    def run_inference(self):
        """Run stream inference (only inference logic)."""
        cfg = self.cfg
        process_dict = self.process_dict
        run_dir = self.run_dir

        # Ensure inference mode
        cfg.inference = True

        model, train_step = setup_model(cfg, process_dict)
        model.eval()
        logging.info(f"Inference from step {train_step}")

        if getattr(cfg.eval, 'compile', False):
            model = torch.compile(model)

        os.makedirs(run_dir, exist_ok=True)
        print('[inference run_dir]:{}'.format(run_dir))

        # Build eval_args, all outputs use run_dir
        eval_args = {
            'save_depth_npy': cfg.eval.save_depth_npy,
            'save_vis_map': cfg.eval.save_vis_map,
            'out_video': cfg.eval.out_video,
            'out_mp4': cfg.eval.out_mp4,
            'use_mamba': cfg.model.use_mamba,
            'resolution': cfg.eval.save_res,
            'print_time': True,
            'use_all_frames': True,
            'use_metrics': False,
            'dummy_timing': cfg.eval.dummy_timing,
            'run_dir': run_dir
        }

        # Resolve stream address
        stream_addr = getattr(cfg.eval, 'stream_url', None) or getattr(cfg.eval, 'url', None)
        if stream_addr is None:
            raise ValueError('Stream address required: set cfg.eval.stream_url or cfg.eval.url')

        warmup = getattr(cfg.eval, 'stream_warmup_frames', 5)
        max_frames = getattr(cfg.eval, 'stream_max_frames', None)
        if max_frames is not None:
            try:
                max_frames = int(max_frames)
                if max_frames <= 0:
                    max_frames = None
            except Exception:
                logging.warning(f"Invalid cfg.eval.stream_max_frames value: {max_frames!r}. Treating as unlimited.")
                max_frames = None
        logging.info(f"Stream max frames set to: {max_frames}")

        logging.info('Using URL input: {}'.format(stream_addr))
        dataset = StreamDataset(stream_url=stream_addr, resolution=cfg.dataset.resolution, warmup_frames=warmup)
        test_dataloader = DataLoader(dataset, batch_size=1, num_workers=0, shuffle=False, drop_last=False)

        # Add frame rate control to prevent processing overload
        import time
        last_frame_time = 0
        target_fps = getattr(cfg.eval, 'target_fps', 30)
        frame_interval = 1.0 / target_fps if target_fps > 0 else 0

        if max_frames is None:
            pbar = tqdm(test_dataloader)
        else:
            pbar = tqdm(test_dataloader, total=max_frames)

        for test_idx, batch in enumerate(pbar):
            current_time = time.time()
            if frame_interval > 0 and current_time - last_frame_time < frame_interval:
                sleep_time = frame_interval - (current_time - last_frame_time)
                time.sleep(sleep_time)
            last_frame_time = time.time()

            if (max_frames is not None) and (test_idx >= int(max_frames)):
                logging.info(f'Reached max_frames {max_frames}, stopping')
                break

            if isinstance(batch, dict):
                batch_tensor = batch['batch']
                save_subdir = run_dir
                os.makedirs(save_subdir, exist_ok=True)
            else:
                batch_tensor = batch
                save_subdir = run_dir

            model_device = next(model.parameters()).device
            if isinstance(batch_tensor, torch.Tensor) and batch_tensor.device != model_device:
                batch_tensor = batch_tensor.to(model_device)

            try:
                with torch.cuda.amp.autocast(dtype=torch.bfloat16):
                    _, img_grid = model(
                        batch_tensor,
                        gif_path=f'{save_subdir}/{os.path.basename(getattr(cfg, "config_dir", "cfg").rstrip("/"))}_{train_step}_{test_idx}.gif',
                        **eval_args
                    )
                if getattr(cfg.eval, 'save_grid', False) and img_grid is not None:
                    img_grid.save(f'{save_subdir}/{os.path.basename(getattr(cfg, "config_dir", "cfg").rstrip("/"))}_{train_step}_{test_idx}.png')
            except Exception as e:
                logging.warning(f"Error processing frame {test_idx}: {e}")
                continue
        try:
            pbar.close()
        except Exception:
            pass

    def cleanup(self):
        # Only destroy process group if it was initialized (distributed mode)
        if hasattr(dist, '_default_pg') and dist._default_pg is not None:
            dist.destroy_process_group()


if __name__ == '__main__':
    # Create processor with default config path
    processor = FlashDepthProcessor()
    try:
        processor.run_inference()
    finally:
        processor.cleanup()
